{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet\n",
    "![](./Picture/alexnet.png)\n",
    "1. 学习的特征可以超过手工的特征\n",
    "2. 在深度学习中，通过卷积层进行卷积操作时，输入图像的大小会在每一步卷积后发生变化。这个变化取决于卷积核的大小、步长（stride）、填充（padding）等参数。下面解释每一步卷积操作后图像大小的变化：\n",
    "3. 维度计算\n",
    "   1. **第一个卷积层**：\n",
    "   - 输入图像大小：假设输入图像的大小为 $W_{\\text{in}} \\times H_{\\text{in}}$，其中 $W_{\\text{in}}$ 表示图像的宽度，$H_{\\text{in}}$ 表示图像的高度。\n",
    "   - 卷积核大小：假设卷积核的大小为 $K \\times K$，这里是 $11 \\times 11$。\n",
    "   - 步长：假设步长为 $S$，这里是 4。\n",
    "   - 填充：通常在AlexNet等网络中，第一个卷积层会进行填充操作，以保持特征图大小。因此，可以假设填充大小为 $P$。\n",
    "   - 计算得到输出特征图的大小为：\n",
    "     $$\n",
    "     \n",
    "     W_{\\text{out}} = \\left\\lfloor \\frac{W_{\\text{in}} + 2P - K}{S} \\right\\rfloor + 1\n",
    "     \\\\\n",
    "     H_{\\text{out}} = \\left\\lfloor \\frac{H_{\\text{in}} + 2P - K}{S} \\right\\rfloor + 1\n",
    "     \n",
    "     $$\n",
    "   2. **第一个池化层**：\n",
    "   - 池化窗口大小：假设池化窗口的大小为 $F \\times F$，这里是 $3 \\times 3$。\n",
    "   - 步长：假设步长为 $S'$，这里是 2。\n",
    "   - 计算得到输出特征图的大小为：\n",
    "     $$\n",
    "     W_{\\text{out}} = \\left\\lfloor \\frac{W_{\\text{in}} - F}{S'} \\right\\rfloor + 1\n",
    "     \\\\\n",
    "     H_{\\text{out}} = \\left\\lfloor \\frac{H_{\\text{in}} - F}{S'} \\right\\rfloor + 1\n",
    "     $$\n",
    "   3. **后续卷积层**：\n",
    "   - 输入特征图的大小取决于前一层的输出大小。\n",
    "   - 根据每层的卷积核大小、步长和填充，可以使用类似的公式来计算每一层的输出特征图大小。\n",
    "4. 输出通道数表示该卷积层使用了多少个卷积核。\n",
    "   1. 因此，**如果卷积核数量小于输出通道数，是合理的。这意味着每个输出通道是由多个卷积核共同作用在输入上得到的，这种设计称为多通道卷积。**在这种情况下，每个输出通道都会有自己的一组卷积核，用于提取不同的特征。\n",
    "5. 数据增强和Dropout：为了防止过拟合，AlexNet 引入了数据增强和 Dropout 技术。数据增强可以通过对图像进行旋转、翻转、裁剪等变换，增加训练数据的多样性，提高模型的泛化能力。Dropout 则是在训练过程中随机删除一定比例的神经元，强制网络学习多个互不相同的子网络，从而提高网络的泛化能力。Dropout简单来说就是在前向传播的时候，让某个神经元的激活值以一定的概率p停止工作，这样可以使模型泛化性更强，因为它不会太依赖某些局部的特征。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "import d2lzh_pytorch as d2l\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 96, 11, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2),#kernel_size, stride\n",
    "            nn.Conv2d(96, 256, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2),\n",
    "            #in_channels, out_channels, kernel_size, stride, padding\n",
    "            nn.Conv2d(256, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256*5*5, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            # 输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000\n",
    "            nn.Linear(4096, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "            feature = self.conv(img)\n",
    "            output = self.fc(feature.view(img.shape[0], -1))\n",
    "            return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 0.6393, train acc 0.757, test acc 0.856, time 71.4 sec\n",
      "epoch 2, loss 0.3493, train acc 0.871, test acc 0.881, time 71.4 sec\n",
      "epoch 3, loss 0.2952, train acc 0.891, test acc 0.894, time 68.6 sec\n",
      "epoch 4, loss 0.2592, train acc 0.904, test acc 0.899, time 68.7 sec\n",
      "epoch 5, loss 0.2379, train acc 0.913, test acc 0.901, time 68.5 sec\n"
     ]
    }
   ],
   "source": [
    "# 本函数已保存在d2lzh_pytorch包中方便以后使用\n",
    "def load_data_fashion_mnist(batch_size, resize=None, root='./Datasets/FashionMNIST'):\n",
    "    trans = []\n",
    "    if resize:\n",
    "        trans.append(torchvision.transforms.Resize(size=resize))\n",
    "\n",
    "    #将PIL图像或numpy.ndarray转换为Tensor，并且对图像进行归一化处理，即将图像的像素值缩放到[0, 1]范围内。\n",
    "    trans.append(torchvision.transforms.ToTensor())\n",
    "    #将一系列的图像转换操作组合成一个整体的转换操作\n",
    "    transform = torchvision.transforms.Compose(trans)\n",
    "\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=True, transform=transform)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=transform)\n",
    "\n",
    "    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_iter, test_iter\n",
    "\n",
    "batch_size = 128\n",
    "# 如出现“out of memory”的报错信息，可减小batch_size或resize\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=224)\n",
    "net = AlexNet()\n",
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
